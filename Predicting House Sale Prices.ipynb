{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting House Sale Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will work with housing data for the city of Ames, Iowa, United States from 2006 to 2010.\n",
    "\n",
    "Let's start by setting up a pipeline of functions that will let us quickly iterate on different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('AmesHousing.tsv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour    ...     Pool Area Pool QC  Fence  \\\n",
       "0   NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
       "1   NaN       Reg          Lvl    ...             0     NaN  MnPrv   \n",
       "2   NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
       "3   NaN       Reg          Lvl    ...             0     NaN    NaN   \n",
       "4   NaN       IR1          Lvl    ...             0     NaN  MnPrv   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0          NaN        0       5    2010       WD           Normal     215000  \n",
       "1          NaN        0       6    2010       WD           Normal     105000  \n",
       "2         Gar2    12500       6    2010       WD           Normal     172000  \n",
       "3          NaN        0       4    2010       WD           Normal     244000  \n",
       "4          NaN        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):  \n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "\n",
    "    numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    model = LinearRegression()\n",
    "    model.fit(train[features], train[\"SalePrice\"])\n",
    "    predictions = model.predict(test[features])\n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "transform_df = transform_features(df)\n",
    "final_df = select_features(transform_df)\n",
    "rmse = train_and_test(final_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove numerical columns that contain more than 5% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_vals = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_cols = missing_vals[missing_vals>len(df)*0.05].index\n",
    "df = df.drop(missing_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical columns we will remove all columns that have at least one mising value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_missing_vals = df.select_dtypes(include=['object']).isnull().sum()\n",
    "text_missing_cols = text_missing_vals[text_missing_vals>0].index\n",
    "df = df.drop(text_missing_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2930, 64)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining numerical columns we well fill in the `NaN` values with the most common value in that column since the mean for columns such as `Garage Cars` wouldn't make much sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['int', \"float\"]).isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cols = num_cols[num_cols >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Bsmt Full Bath': 0.0,\n",
       "  'Bsmt Half Bath': 0.0,\n",
       "  'Bsmt Unf SF': 0.0,\n",
       "  'BsmtFin SF 1': 0.0,\n",
       "  'BsmtFin SF 2': 0.0,\n",
       "  'Garage Area': 0.0,\n",
       "  'Garage Cars': 2.0,\n",
       "  'Mas Vnr Area': 0.0,\n",
       "  'Total Bsmt SF': 0.0}]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = df[num_cols.index].mode().to_dict('records')\n",
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(mode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the span for the years the houses were built and remodeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "Name: Years Before Sale, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Years Before Sale'] = df['Yr Sold'] - df['Year Built']\n",
    "df['Years Before Sale'][df['Years Before Sale'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "Name: Years Since Remodel, dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Years Since Remodel'] = df['Yr Sold'] - df['Year Remod/Add']\n",
    "df['Years Since Remodel'][df['Years Since Remodel'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop the negative years which resulted from an input error and remove the original years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop([1702, 2180, 2181], axis=0)\n",
    "df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll drop columns that:\n",
    "\n",
    "* aren't useful for ML\n",
    "* leak data about the final sale\n",
    "\n",
    "The columns that leak information about the final sale are those that we wouldn't know at the time we are making the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Drop columns that aren't useful\n",
    "df = df.drop([\"PID\", \"Order\"], axis=1)\n",
    "\n",
    "## Drop columns that leak info about the final sale\n",
    "df = df.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll updated the transform_features() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    #Drop columns with more than 5% of missing values\n",
    "    missing_vals = df.isnull().sum()\n",
    "    missing_cols = missing_vals[missing_vals>len(df)*0.05].index\n",
    "    df = df.drop(missing_cols, axis=1)\n",
    "    \n",
    "    #Drop text columns that contain missing values\n",
    "    text_missing_vals = df.select_dtypes(include=['object']).isnull().sum()\n",
    "    text_missing_cols = text_missing_vals[text_missing_vals>0].index\n",
    "    df = df.drop(text_missing_cols, axis=1)\n",
    "    \n",
    "    #For remaining num columns, fill in missing value with the column mode\n",
    "    num_cols = df.select_dtypes(include=['int', \"float\"]).isnull().sum().sort_values(ascending=False)\n",
    "    num_cols = num_cols[num_cols >= 1]\n",
    "    mode = df[num_cols.index].mode().to_dict('records')\n",
    "    df = df.fillna(mode[0])\n",
    "    \n",
    "    #Transform years values and drop columns which leak info\n",
    "    df['Years Before Sale'] = df['Yr Sold'] - df['Year Built']\n",
    "    df['Years Since Remodel'] = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1)\n",
    "    \n",
    "    df = df.drop([\"PID\", \"Order\"], axis=1)\n",
    "    df = df.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's retrain the model with the transformed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55275.36731241307"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "final_df = select_features(transform_df)\n",
    "rmse = train_and_test(final_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "We still have 58 features left which is bound to overfit in a linear regression, so we will now do feature selection based on the features correlation and each invidiual column's variance.\n",
    "\n",
    "Let's generate correlation heatmap matrix of the numerical features in the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_df = transform_df.select_dtypes(include=['int', 'float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice              1.000000\n",
       "Overall Qual           0.801206\n",
       "Gr Liv Area            0.717596\n",
       "Garage Cars            0.648361\n",
       "Total Bsmt SF          0.644012\n",
       "Garage Area            0.641425\n",
       "1st Flr SF             0.635185\n",
       "Years Before Sale      0.558979\n",
       "Full Bath              0.546118\n",
       "Years Since Remodel    0.534985\n",
       "Mas Vnr Area           0.506983\n",
       "TotRms AbvGrd          0.498574\n",
       "Fireplaces             0.474831\n",
       "BsmtFin SF 1           0.439284\n",
       "Wood Deck SF           0.328183\n",
       "Open Porch SF          0.316262\n",
       "Half Bath              0.284871\n",
       "Bsmt Full Bath         0.276258\n",
       "2nd Flr SF             0.269601\n",
       "Lot Area               0.267520\n",
       "Bsmt Unf SF            0.182751\n",
       "Bedroom AbvGr          0.143916\n",
       "Enclosed Porch         0.128685\n",
       "Kitchen AbvGr          0.119760\n",
       "Screen Porch           0.112280\n",
       "Overall Cond           0.101540\n",
       "MS SubClass            0.085128\n",
       "Pool Area              0.068438\n",
       "Low Qual Fin SF        0.037629\n",
       "Bsmt Half Bath         0.035875\n",
       "3Ssn Porch             0.032268\n",
       "Misc Val               0.019273\n",
       "BsmtFin SF 2           0.006127\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = num_df.corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep the numerical columns that have a correlation higher than 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice              1.000000\n",
       "Overall Qual           0.801206\n",
       "Gr Liv Area            0.717596\n",
       "Garage Cars            0.648361\n",
       "Total Bsmt SF          0.644012\n",
       "Garage Area            0.641425\n",
       "1st Flr SF             0.635185\n",
       "Years Before Sale      0.558979\n",
       "Full Bath              0.546118\n",
       "Years Since Remodel    0.534985\n",
       "Mas Vnr Area           0.506983\n",
       "TotRms AbvGrd          0.498574\n",
       "Fireplaces             0.474831\n",
       "BsmtFin SF 1           0.439284\n",
       "Wood Deck SF           0.328183\n",
       "Open Porch SF          0.316262\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr[corr>0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2927, 58)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_df = transform_df.drop(corr[corr<0.3].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "for col in nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        categorical_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS Zoning',\n",
       " 'Street',\n",
       " 'Land Contour',\n",
       " 'Lot Config',\n",
       " 'Neighborhood',\n",
       " 'Condition 1',\n",
       " 'Condition 2',\n",
       " 'Bldg Type',\n",
       " 'House Style',\n",
       " 'Roof Style',\n",
       " 'Roof Matl',\n",
       " 'Exterior 1st',\n",
       " 'Exterior 2nd',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'Central Air']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood    28\n",
       "Exterior 2nd    17\n",
       "Exterior 1st    16\n",
       "Condition 1      9\n",
       "Roof Matl        8\n",
       "House Style      8\n",
       "Condition 2      8\n",
       "MS Zoning        7\n",
       "Heating          6\n",
       "Foundation       6\n",
       "Roof Style       6\n",
       "Bldg Type        5\n",
       "Lot Config       5\n",
       "Land Contour     4\n",
       "Central Air      2\n",
       "Street           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = transform_df[categorical_features].apply(lambda col: len(col.value_counts())).sort_values(ascending=False)\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we dummy code column with many hundreds of unique, hundreds of columns will need to be added back to the data frame. Therefore we will only keep those that have less than 5 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_df = transform_df.drop(unique_values[unique_values>5].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2927, 30)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll check for low variability in the data by looking at columns that have a few unique values but more than 95% of the values in the column belong to a specific category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = []\n",
    "for col in categorical_features:\n",
    "    if col in transform_df.columns:\n",
    "        cat_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Street', 'Land Contour', 'Lot Config', 'Bldg Type', 'Central Air']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pave    99.590024\n",
      "Grvl     0.409976\n",
      "Name: Street, dtype: float64\n",
      "\n",
      "\n",
      "Lvl    89.921421\n",
      "HLS     4.099761\n",
      "Bnk     3.928937\n",
      "Low     2.049880\n",
      "Name: Land Contour, dtype: float64\n",
      "\n",
      "\n",
      "Inside     73.044072\n",
      "Corner     17.423984\n",
      "CulDSac     6.149641\n",
      "FR2         2.903997\n",
      "FR3         0.478305\n",
      "Name: Lot Config, dtype: float64\n",
      "\n",
      "\n",
      "1Fam      82.746840\n",
      "TwnhsE     7.960369\n",
      "Duplex     3.723949\n",
      "Twnhs      3.450632\n",
      "2fmCon     2.118210\n",
      "Name: Bldg Type, dtype: float64\n",
      "\n",
      "\n",
      "Y    93.303724\n",
      "N     6.696276\n",
      "Name: Central Air, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in cat_features:\n",
    "    print(transform_df[col].value_counts(normalize=True)*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the `Street` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_df.drop('Street', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll actualy encode the cat features as categorical (now they are `object`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_cols = transform_df.select_dtypes(include=['object'])\n",
    "for col in text_cols:\n",
    "    transform_df[col] = transform_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now dummy these features using pandas .get_dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(transform_df.select_dtypes(include=['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concatenate the dataframes\n",
    "transform_df = pd.concat([transform_df, dummies], axis=1)\n",
    "\n",
    "#Drop the original cat features\n",
    "transform_df.drop(text_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2927, 72)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll put all the logic so far in the `select_features()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(df, corr_threshold=0.3, unique_val_threshold=10):\n",
    "    #Selecting features that have a correlation higher than 0.3 with the target\n",
    "    num_df = df.select_dtypes(include=['int', 'float'])\n",
    "    corr = num_df.corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "    transform_df = df.drop(corr[corr<corr_threshold].index, axis=1)\n",
    "    \n",
    "    #Transforming the text columns\n",
    "    categorical_features = [\n",
    "         'MS Zoning',\n",
    "         'Street',\n",
    "         'Land Contour',\n",
    "         'Lot Config',\n",
    "         'Neighborhood',\n",
    "         'Condition 1',\n",
    "         'Condition 2',\n",
    "         'Bldg Type',\n",
    "         'House Style',\n",
    "         'Roof Style',\n",
    "         'Roof Matl',\n",
    "         'Exterior 1st',\n",
    "         'Exterior 2nd',\n",
    "         'Foundation',\n",
    "         'Heating',\n",
    "         'Central Air']\n",
    "    unique_values = transform_df[categorical_features].apply(lambda col: len(col.value_counts())).sort_values(ascending=False)\n",
    "    transform_df = transform_df.drop(unique_values[unique_values>unique_val_threshold].index, axis=1)\n",
    "    \n",
    "    #Removing low variability features\n",
    "    cat_features = []\n",
    "    for col in categorical_features:\n",
    "        if col in transform_df.columns:\n",
    "            cat_features.append(col)\n",
    "    transform_df.drop('Street', axis=1, inplace=True)\n",
    "    \n",
    "    #Get dummies for cat variables\n",
    "    text_cols = transform_df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        transform_df[col] = transform_df[col].astype('category')\n",
    "    dummies = pd.get_dummies(transform_df.select_dtypes(include=['category']))\n",
    "    \n",
    "    #Concatenate the dataframes\n",
    "    transform_df = pd.concat([transform_df, dummies], axis=1)\n",
    "\n",
    "    #Drop the original cat features\n",
    "    transform_df.drop(text_cols, axis=1, inplace=True)\n",
    "    \n",
    "    return transform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33278.76501848715"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "final_df = select_features(transform_df)\n",
    "rmse = train_and_test(final_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decrease the threshold for unique variables in the categorical columns to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32904.16085766734"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "final_df = select_features(transform_df, 0.3, 5 )\n",
    "rmse = train_and_test(final_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "For the final part, we will perform k-fold cross validation.\n",
    "\n",
    "We will update the `train_and_test` function to take an optional input `k` for number of folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    #If k=0, implement a holdout validation\n",
    "    if k == 0:\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        model.fit(train[features], train[\"SalePrice\"])\n",
    "        pred = model.predict(test[features])\n",
    "        mse = mean_squared_error(test[\"SalePrice\"], pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        return rmse\n",
    "    \n",
    "    if k > 0:\n",
    "        folds = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_vals = []\n",
    "        i=0\n",
    "        for train_ix, test_ix, in folds.split(df):\n",
    "            i += 1\n",
    "            train = df.iloc[train_ix]\n",
    "            test = df.iloc[test_ix]\n",
    "            model.fit(train[features], train[\"SalePrice\"])\n",
    "            pred = model.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_vals.append(rmse)\n",
    "            print(\"Fold {}: {}\".format(i, rmse))\n",
    "        average_rmse = np.mean(rmse_vals)\n",
    "        print(\"Average: {} \".format(average_rmse))\n",
    "        \n",
    "        return average_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 27632.699089861715\n",
      "Fold 2: 23344.792308420587\n",
      "Fold 3: 29164.435907126324\n",
      "Fold 4: 23729.5439951428\n",
      "Fold 5: 24035.673865097604\n",
      "Fold 6: 24277.88329240221\n",
      "Fold 7: 30298.739255807814\n",
      "Fold 8: 47821.79058172581\n",
      "Fold 9: 22799.754528317902\n",
      "Fold 10: 33244.171625548406\n",
      "Average: 28634.948444945116 \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "final_df = select_features(transform_df, 0.3, 5 )\n",
    "rmse = train_and_test(final_df, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that 10 k-fold cross validation performs better than a simple holdout validation: RMSE - 28634 vs RMSE - 32904. The most important skill when it comes to feature engineering is domain expertise which helps in coming up with new ways of extracting predictive information from the orignal variables."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
